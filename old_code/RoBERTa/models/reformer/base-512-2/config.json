{
    "from_cp": "init.model",
    "from_pretrained_roberta": false,
    "model": {
        "mixed_precision": true,
        "shared_weight": false,
        "vocab_size": 50265,
        "num_sen_type": 1,
        "max_seq_len": 512,
        "embedding_dim": 768,
        "dim": 768,
        "hidden_dim": 3072,
        "num_layers": 12,
        "dropout_prob": 0.1,
        "num_head": 12,
        "head_dim": 64,
        "model_type": "reformer",
        "num_hash": 2
    },
    "dataset": "datasets/roberta-train-sl_512-bs_512-nb_1000-ne_200-bookcorpus-english_wiki",
    "val_dataset": "datasets/roberta-val-sl_512-bs_512-nb_200-ne_1-bookcorpus-english_wiki-transformer/epoch-0000.pickle.gzip",
    "pretraining_setting": {
        "learning_rate": 5e-05,
        "warmup": 0.05,
        "batches_per_report": 10,
        "batches_per_epoch": 1000,
        "epoch": 20
    },
    "gpu_setting": {
        "inst_per_gpu": 16
    }
}